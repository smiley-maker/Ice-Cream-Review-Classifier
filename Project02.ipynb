{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project02.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FJ68tf2U8wlY",
        "draXJlwzhShk",
        "XK6hSBZWLSQg",
        "JKwg3t0hhttA",
        "HiEnsQ7b4u0W",
        "PEh56xZ1rbYH",
        "O_qesX9FJZHm"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFJWdL6y7FHo"
      },
      "source": [
        "\n",
        "<h1><center><b>Project Two</b></center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpaDve8t72pt"
      },
      "source": [
        "<h3><center><i>Jordan Sinclair</i></center></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ68tf2U8wlY"
      },
      "source": [
        "# <h1><center><b>Notebook Setup</b></center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6iWgQnbnBTj"
      },
      "source": [
        "When you are done with this notebook, run the following code cell to unmount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D78AM1fFt2ty",
        "outputId": "2efb2d49-e8a1-40e7-bbb5-5ca2069fc55e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "print('All changes made in this colab session should now be visible in Drive.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All changes made in this colab session should now be visible in Drive.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPzhOpDUvfAL"
      },
      "source": [
        "The following code cell installs additional dependencies required to run the Jupyter Notebooks used in this class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjPAPnLLTN4x",
        "outputId": "be7a1465-8153-4eb7-cc68-415c4566138a"
      },
      "source": [
        "# Add additional Python packages that we will be using in class\n",
        "!apt install graphviz build-essential checkinstall imagemagick\n",
        "# Base Python packages to run example Jupyter Notebooks\n",
        "!pip install watermark pyprind mlxtend\n",
        "# Python packages to visualize Decision Tree Classifiers\n",
        "!pip install pydotplus graphviz pyparsing\n",
        "# Python packages for Natrual Language Processing\n",
        "!pip install nltk\n",
        "# Python packages for Flask-based web applications\n",
        "!pip install flask wtforms\n",
        "# Python packages for TensorFlow\n",
        "!pip install tensorflow tensorflow-datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.4ubuntu1).\n",
            "graphviz is already the newest version (2.40.1-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  file fonts-droid-fallback fonts-noto-mono ghostscript gsfonts\n",
            "  imagemagick-6-common imagemagick-6.q16 libcupsfilters1 libcupsimage2\n",
            "  libdjvulibre-text libdjvulibre21 libgs9 libgs9-common libijs-0.35\n",
            "  libjbig2dec0 liblqr-1-0 libmagic-mgc libmagic1 libmagickcore-6.q16-3\n",
            "  libmagickcore-6.q16-3-extra libmagickwand-6.q16-3 libnetpbm10 libwmf0.2-7\n",
            "  netpbm poppler-data\n",
            "Suggested packages:\n",
            "  gettext fonts-noto ghostscript-x imagemagick-doc autotrace cups-bsd | lpr\n",
            "  | lprng enscript gimp gnuplot grads hp2xx html2ps libwmf-bin mplayer povray\n",
            "  radiance sane-utils texlive-base-bin transfig ufraw-batch inkscape\n",
            "  libjxr-tools libwmf0.2-7-gtk poppler-utils fonts-japanese-mincho\n",
            "  | fonts-ipafont-mincho fonts-japanese-gothic | fonts-ipafont-gothic\n",
            "  fonts-arphic-ukai fonts-arphic-uming fonts-nanum\n",
            "The following NEW packages will be installed:\n",
            "  checkinstall file fonts-droid-fallback fonts-noto-mono ghostscript gsfonts\n",
            "  imagemagick imagemagick-6-common imagemagick-6.q16 libcupsfilters1\n",
            "  libcupsimage2 libdjvulibre-text libdjvulibre21 libgs9 libgs9-common\n",
            "  libijs-0.35 libjbig2dec0 liblqr-1-0 libmagic-mgc libmagic1\n",
            "  libmagickcore-6.q16-3 libmagickcore-6.q16-3-extra libmagickwand-6.q16-3\n",
            "  libnetpbm10 libwmf0.2-7 netpbm poppler-data\n",
            "0 upgraded, 27 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 18.8 MB of archives.\n",
            "After this operation, 72.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblqr-1-0 amd64 0.4.2-2.1 [27.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick-6-common all 8:6.9.7.4+dfsg-16ubuntu6.11 [60.2 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6.q16-3 amd64 8:6.9.7.4+dfsg-16ubuntu6.11 [1,619 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickwand-6.q16-3 amd64 8:6.9.7.4+dfsg-16ubuntu6.11 [294 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.4 [22.1 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 checkinstall amd64 1.6.2-4ubuntu2 [97.1 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.8 [18.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.14 [5,092 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.14 [2,265 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ghostscript amd64 9.26~dfsg+0-0ubuntu0.18.04.14 [51.3 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.4 [3,120 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick-6.q16 amd64 8:6.9.7.4+dfsg-16ubuntu6.11 [423 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick amd64 8:6.9.7.4+dfsg-16ubuntu6.11 [14.2 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdjvulibre-text all 3.5.27.1-8ubuntu0.4 [49.4 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdjvulibre21 amd64 3.5.27.1-8ubuntu0.4 [561 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwmf0.2-7 amd64 0.2.8.4-12 [150 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6.q16-3-extra amd64 8:6.9.7.4+dfsg-16ubuntu6.11 [62.4 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnetpbm10 amd64 2:10.0-15.3build1 [58.0 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 netpbm amd64 2:10.0-15.3build1 [1,017 kB]\n",
            "Fetched 18.8 MB in 2s (8,027 kB/s)\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 148486 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Selecting previously unselected package liblqr-1-0:amd64.\n",
            "Preparing to unpack .../01-liblqr-1-0_0.4.2-2.1_amd64.deb ...\n",
            "Unpacking liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Selecting previously unselected package imagemagick-6-common.\n",
            "Preparing to unpack .../02-imagemagick-6-common_8%3a6.9.7.4+dfsg-16ubuntu6.11_all.deb ...\n",
            "Unpacking imagemagick-6-common (8:6.9.7.4+dfsg-16ubuntu6.11) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-3:amd64.\n",
            "Preparing to unpack .../03-libmagickcore-6.q16-3_8%3a6.9.7.4+dfsg-16ubuntu6.11_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.11) ...\n",
            "Selecting previously unselected package libmagickwand-6.q16-3:amd64.\n",
            "Preparing to unpack .../04-libmagickwand-6.q16-3_8%3a6.9.7.4+dfsg-16ubuntu6.11_amd64.deb ...\n",
            "Unpacking libmagickwand-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.11) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../05-poppler-data_0.4.8-2_all.deb ...\n",
            "Unpacking poppler-data (0.4.8-2) ...\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "Preparing to unpack .../06-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../07-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package file.\n",
            "Preparing to unpack .../08-file_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking file (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package checkinstall.\n",
            "Preparing to unpack .../09-checkinstall_1.6.2-4ubuntu2_amd64.deb ...\n",
            "Unpacking checkinstall (1.6.2-4ubuntu2) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../10-fonts-noto-mono_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-mono (20171026-2) ...\n",
            "Selecting previously unselected package libcupsimage2:amd64.\n",
            "Preparing to unpack .../11-libcupsimage2_2.2.7-1ubuntu2.8_amd64.deb ...\n",
            "Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../12-libijs-0.35_0.35-13_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-13) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../13-libjbig2dec0_0.13-6_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.13-6) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../14-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.14_all.deb ...\n",
            "Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../15-libgs9_9.26~dfsg+0-0ubuntu0.18.04.14_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../16-ghostscript_9.26~dfsg+0-0ubuntu0.18.04.14_amd64.deb ...\n",
            "Unpacking ghostscript (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../17-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.4_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Selecting previously unselected package imagemagick-6.q16.\n",
            "Preparing to unpack .../18-imagemagick-6.q16_8%3a6.9.7.4+dfsg-16ubuntu6.11_amd64.deb ...\n",
            "Unpacking imagemagick-6.q16 (8:6.9.7.4+dfsg-16ubuntu6.11) ...\n",
            "Selecting previously unselected package imagemagick.\n",
            "Preparing to unpack .../19-imagemagick_8%3a6.9.7.4+dfsg-16ubuntu6.11_amd64.deb ...\n",
            "Unpacking imagemagick (8:6.9.7.4+dfsg-16ubuntu6.11) ...\n",
            "Selecting previously unselected package libcupsfilters1:amd64.\n",
            "Preparing to unpack .../20-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n",
            "Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Selecting previously unselected package libdjvulibre-text.\n",
            "Preparing to unpack .../21-libdjvulibre-text_3.5.27.1-8ubuntu0.4_all.deb ...\n",
            "Unpacking libdjvulibre-text (3.5.27.1-8ubuntu0.4) ...\n",
            "Selecting previously unselected package libdjvulibre21:amd64.\n",
            "Preparing to unpack .../22-libdjvulibre21_3.5.27.1-8ubuntu0.4_amd64.deb ...\n",
            "Unpacking libdjvulibre21:amd64 (3.5.27.1-8ubuntu0.4) ...\n",
            "Selecting previously unselected package libwmf0.2-7:amd64.\n",
            "Preparing to unpack .../23-libwmf0.2-7_0.2.8.4-12_amd64.deb ...\n",
            "Unpacking libwmf0.2-7:amd64 (0.2.8.4-12) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-3-extra:amd64.\n",
            "Preparing to unpack .../24-libmagickcore-6.q16-3-extra_8%3a6.9.7.4+dfsg-16ubuntu6.11_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-3-extra:amd64 (8:6.9.7.4+dfsg-16ubuntu6.11) ...\n",
            "Selecting previously unselected package libnetpbm10.\n",
            "Preparing to unpack .../25-libnetpbm10_2%3a10.0-15.3build1_amd64.deb ...\n",
            "Unpacking libnetpbm10 (2:10.0-15.3build1) ...\n",
            "Selecting previously unselected package netpbm.\n",
            "Preparing to unpack .../26-netpbm_2%3a10.0-15.3build1_amd64.deb ...\n",
            "Unpacking netpbm (2:10.0-15.3build1) ...\n",
            "Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up imagemagick-6-common (8:6.9.7.4+dfsg-16ubuntu6.11) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Setting up poppler-data (0.4.8-2) ...\n",
            "Setting up libdjvulibre-text (3.5.27.1-8ubuntu0.4) ...\n",
            "Setting up libnetpbm10 (2:10.0-15.3build1) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up fonts-noto-mono (20171026-2) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Setting up liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Setting up libjbig2dec0:amd64 (0.13-6) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-13) ...\n",
            "Setting up netpbm (2:10.0-15.3build1) ...\n",
            "Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up libwmf0.2-7:amd64 (0.2.8.4-12) ...\n",
            "Setting up libmagickcore-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.11) ...\n",
            "Setting up libdjvulibre21:amd64 (3.5.27.1-8ubuntu0.4) ...\n",
            "Setting up ghostscript (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up file (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagickwand-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.11) ...\n",
            "Setting up checkinstall (1.6.2-4ubuntu2) ...\n",
            "Setting up imagemagick-6.q16 (8:6.9.7.4+dfsg-16ubuntu6.11) ...\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare (compare) in auto mode\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare-im6 (compare-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate (animate) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate-im6 (animate-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert (convert) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert-im6 (convert-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite (composite) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite-im6 (composite-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure (conjure) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure-im6 (conjure-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import (import) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import-im6 (import-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify (identify) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify-im6 (identify-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream (stream) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream-im6 (stream-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display (display) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display-im6 (display-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage (montage) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage-im6 (montage-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify (mogrify) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify-im6 (mogrify-im6) in auto mode\n",
            "Setting up libmagickcore-6.q16-3-extra:amd64 (8:6.9.7.4+dfsg-16ubuntu6.11) ...\n",
            "Setting up imagemagick (8:6.9.7.4+dfsg-16ubuntu6.11) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting watermark\n",
            "  Downloading watermark-2.2.0-py2.py3-none-any.whl (6.8 kB)\n",
            "Collecting pyprind\n",
            "  Downloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from watermark) (5.5.0)\n",
            "Collecting importlib-metadata<3.0\n",
            "  Downloading importlib_metadata-2.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<3.0->watermark) (3.5.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (57.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=1.5.1->mlxtend) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.0.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (5.0.5)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (4.4.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->watermark) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->watermark) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->watermark) (0.7.0)\n",
            "Installing collected packages: importlib-metadata, watermark, pyprind\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.6.3\n",
            "    Uninstalling importlib-metadata-4.6.3:\n",
            "      Successfully uninstalled importlib-metadata-4.6.3\n",
            "Successfully installed importlib-metadata-2.1.1 pyprind-2.11.3 watermark-2.2.0\n",
            "Requirement already satisfied: pydotplus in /usr/local/lib/python3.7/dist-packages (2.0.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (0.10.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (2.4.7)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (1.1.4)\n",
            "Collecting wtforms\n",
            "  Downloading WTForms-2.3.3-py2.py3-none-any.whl (169 kB)\n",
            "\u001b[K     |████████████████████████████████| 169 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask) (2.0.1)\n",
            "Installing collected packages: wtforms\n",
            "Successfully installed wtforms-2.3.3\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.34.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (0.3.4)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (5.2.2)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (21.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (4.62.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (0.16.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (1.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.53.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0UX1g1_gQHP"
      },
      "source": [
        "The following code cell defines a variable equal to the location inside your Google Drive where you copied the ch03 folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETNDrge2gQHW"
      },
      "source": [
        "##### TODO CHANGE THIS TO THE PATH IN GOOGLE DRIVE WHERE YOU COPIED THE ch03 FOLDER #####\n",
        "google_drive_root='/machine-learning/Project Two Jordan Sinclair'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1uDwAzrhfmC"
      },
      "source": [
        "google_drive_mount_location = '/content/drive'\n",
        "google_file_prefix=google_drive_mount_location + '/My Drive/' + google_drive_root + '/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6HBVmy6fmNx"
      },
      "source": [
        "The following code cell mounts your Google Drive into the runtime of the workbook, so that you can access files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CRN2nETfghz",
        "outputId": "a40c1529-50a2-4614-90cc-8c6254df6bd9"
      },
      "source": [
        "# Read more here: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=D78AM1fFt2ty\n",
        "from google.colab import drive\n",
        "drive.mount(google_drive_mount_location)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "draXJlwzhShk"
      },
      "source": [
        "# <center><b>Imports</b></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9HIqkbchdD6"
      },
      "source": [
        "#Imports for data preprocessing:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "import sys\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import os\n",
        "\n",
        "#For Website Creation:\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "import sqlite3\n",
        "\n",
        "#For machine learning models:\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK6hSBZWLSQg"
      },
      "source": [
        "# <h1><center><b>Experiment Objective</b></center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkZk9faiZ0Ln"
      },
      "source": [
        "I wanted to create a machine learning algorithm that will take a user's Ben & Jerry's icecream review and describe whether it is positive or negative. I originally planned to use multiclass categorization with positive, negative, and neutral options, but the neutral class didn't was very small in comparison to the other two and the model had trouble differentiating it. \n",
        "\n",
        "The data I chose to use came from a Kaggle dataset that contained numerous ice cream related information. The link to the complete dataset is:\n",
        "\n",
        "https://www.kaggle.com/tysonpo/ice-cream-dataset\n",
        "\n",
        "I wasn't sure about the ethicality of using Ben & Jerry's reviews from their website. I couldn't find any kind of Terms of Service that covered this, so I decided to reach out to the company. They actually wrote back to me and explained that:\n",
        "\n",
        "\"Reviews on the web are public so feel free to use them for your project! Thanks for asking :)\"\n",
        "\n",
        "I really appreciate the company for taking time to respond to me. The data from Ben and Jerry's reviews had several features that weren't necessary for the sentiment analysis I wanted to complete. I decided to start by removing those extra columns, as described below. Afterwords, the dataset only consisted of the actual review text and the number of stars given. I decided to designate the negative class as 1, 2, or 3 stars and the positive as 4 or 5 stars. I decided to use the first 7000 samples of the shuffled data for the training set. This left about 1000 samples for the test dataset. \n",
        "\n",
        "At the end of this project, I hope to have a working website that will provide the overall sentiment of a user's input review and that will readjust the sentiment if the first estimate is incorrect. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKwg3t0hhttA"
      },
      "source": [
        "# <h1><center><b>Data Collection</b></center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIODPfuyMtbi"
      },
      "source": [
        "I chose to use icecream review data from Ben & Jerrys' website. This data was retreived from a dataset on Kaggle that contained numerous ice cream related information, including different brand reviews, flavors, etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "6RHkAgqEhyg4",
        "outputId": "75cf1b3e-0cb2-40b2-a0be-7f1248c9e75d"
      },
      "source": [
        "#Location of the dataset in Google Drive \n",
        "data = google_file_prefix + 'reviews.csv'\n",
        "\n",
        "#If using a version before 3.0, the dataset must be converted to unicode.\n",
        "if (sys.version_info < (3, 0)):\n",
        "    data = unicode(data)\n",
        "\n",
        "#Reads the csv data into a Pandas DataFrame, df. \n",
        "df = pd.read_csv(data, header=None, encoding='utf-8')\n",
        "\n",
        "#Shows the first five rows of the dataset. \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>key</td>\n",
              "      <td>author</td>\n",
              "      <td>date</td>\n",
              "      <td>stars</td>\n",
              "      <td>title</td>\n",
              "      <td>helpful_yes</td>\n",
              "      <td>helpful_no</td>\n",
              "      <td>text</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0_bj</td>\n",
              "      <td>Ilovebennjerry</td>\n",
              "      <td>2017-04-15</td>\n",
              "      <td>3</td>\n",
              "      <td>Not enough brownies!</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>Super good, don't get me wrong. But I came for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0_bj</td>\n",
              "      <td>Sweettooth909</td>\n",
              "      <td>2020-01-05</td>\n",
              "      <td>5</td>\n",
              "      <td>I’m OBSESSED with this pint!</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>I decided to try it out although I’m not a hug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0_bj</td>\n",
              "      <td>LaTanga71</td>\n",
              "      <td>2018-04-26</td>\n",
              "      <td>3</td>\n",
              "      <td>My favorite...More Caramel Please</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>My caramel core begins to disappear about half...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0_bj</td>\n",
              "      <td>chicago220</td>\n",
              "      <td>2018-01-14</td>\n",
              "      <td>5</td>\n",
              "      <td>Obsessed!!!</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>Why are people complaining about the blonde br...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0  ...                                                  7\n",
              "0   key  ...                                               text\n",
              "1  0_bj  ...  Super good, don't get me wrong. But I came for...\n",
              "2  0_bj  ...  I decided to try it out although I’m not a hug...\n",
              "3  0_bj  ...  My caramel core begins to disappear about half...\n",
              "4  0_bj  ...  Why are people complaining about the blonde br...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiEnsQ7b4u0W"
      },
      "source": [
        "# <h1><center><b>Data Processing</b></center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vibbCj8KGsny"
      },
      "source": [
        "First, I removed the first row of the dataset and relabeled the columns since the titles were in the first row. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "-emndlFlFyiq",
        "outputId": "4c846465-db7d-422d-c1ea-81f35609d65d"
      },
      "source": [
        "df.columns = [\"key\", \"author\", \"date\", \"stars\", \"title\", \"helpful_yes\", \"helpful_no\", \"text\"]\n",
        "df = df.drop(axis=0, index=0)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>key</th>\n",
              "      <th>author</th>\n",
              "      <th>date</th>\n",
              "      <th>stars</th>\n",
              "      <th>title</th>\n",
              "      <th>helpful_yes</th>\n",
              "      <th>helpful_no</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0_bj</td>\n",
              "      <td>Ilovebennjerry</td>\n",
              "      <td>2017-04-15</td>\n",
              "      <td>3</td>\n",
              "      <td>Not enough brownies!</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>Super good, don't get me wrong. But I came for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0_bj</td>\n",
              "      <td>Sweettooth909</td>\n",
              "      <td>2020-01-05</td>\n",
              "      <td>5</td>\n",
              "      <td>I’m OBSESSED with this pint!</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>I decided to try it out although I’m not a hug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0_bj</td>\n",
              "      <td>LaTanga71</td>\n",
              "      <td>2018-04-26</td>\n",
              "      <td>3</td>\n",
              "      <td>My favorite...More Caramel Please</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>My caramel core begins to disappear about half...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0_bj</td>\n",
              "      <td>chicago220</td>\n",
              "      <td>2018-01-14</td>\n",
              "      <td>5</td>\n",
              "      <td>Obsessed!!!</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>Why are people complaining about the blonde br...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0_bj</td>\n",
              "      <td>Kassidyk</td>\n",
              "      <td>2020-07-24</td>\n",
              "      <td>1</td>\n",
              "      <td>Worst Ice Cream Ever!</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>This ice cream is worst ice cream I’ve ever ta...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    key  ...                                               text\n",
              "1  0_bj  ...  Super good, don't get me wrong. But I came for...\n",
              "2  0_bj  ...  I decided to try it out although I’m not a hug...\n",
              "3  0_bj  ...  My caramel core begins to disappear about half...\n",
              "4  0_bj  ...  Why are people complaining about the blonde br...\n",
              "5  0_bj  ...  This ice cream is worst ice cream I’ve ever ta...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHM82USsHNsQ"
      },
      "source": [
        "Next, I removed some of the columns, since I don't need all of the extra information, including the author, date, key, title, or helpfulness. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2SODkxdHTg2"
      },
      "source": [
        "df = df.drop(axis=1, labels=[\"key\", \"author\", \"date\", \"helpful_yes\", \"helpful_no\", \"title\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "c0xaajtBHZ1A",
        "outputId": "738649d8-7a62-4aed-c9a6-a4614615d268"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Super good, don't get me wrong. But I came for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>I decided to try it out although I’m not a hug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>My caramel core begins to disappear about half...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Why are people complaining about the blonde br...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>This ice cream is worst ice cream I’ve ever ta...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  stars                                               text\n",
              "1     3  Super good, don't get me wrong. But I came for...\n",
              "2     5  I decided to try it out although I’m not a hug...\n",
              "3     3  My caramel core begins to disappear about half...\n",
              "4     5  Why are people complaining about the blonde br...\n",
              "5     1  This ice cream is worst ice cream I’ve ever ta..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcf4s4y-Hqus"
      },
      "source": [
        "Now the data can be shuffled. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "SCCPnRAQHjKh",
        "outputId": "a4050528-2402-4dd4-a856-c3fabe1f9756"
      },
      "source": [
        "np.random.seed(0)\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4838</th>\n",
              "      <td>5</td>\n",
              "      <td>I bought this a week ago for the first time an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>5</td>\n",
              "      <td>My mom and I always get this one every time we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>5</td>\n",
              "      <td>Searched high and low for this flavor. Finally...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5167</th>\n",
              "      <td>5</td>\n",
              "      <td>My favorite mint ice cream on the market and I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1727</th>\n",
              "      <td>5</td>\n",
              "      <td>First of all everyone should try ice cream fla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4932</th>\n",
              "      <td>5</td>\n",
              "      <td>I picked this up with the Red, White and blueb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265</th>\n",
              "      <td>3</td>\n",
              "      <td>Ben and Jerry's is my splurging ice cream. Onc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1654</th>\n",
              "      <td>5</td>\n",
              "      <td>This was a flavor that I went to if I really w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2608</th>\n",
              "      <td>5</td>\n",
              "      <td>This flavor and chunky monkey are by far my fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2733</th>\n",
              "      <td>4</td>\n",
              "      <td>Good ice cream. The best CC ice cream is from ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7943 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     stars                                               text\n",
              "4838     5  I bought this a week ago for the first time an...\n",
              "163      5  My mom and I always get this one every time we...\n",
              "972      5  Searched high and low for this flavor. Finally...\n",
              "5167     5  My favorite mint ice cream on the market and I...\n",
              "1727     5  First of all everyone should try ice cream fla...\n",
              "...    ...                                                ...\n",
              "4932     5  I picked this up with the Red, White and blueb...\n",
              "3265     3  Ben and Jerry's is my splurging ice cream. Onc...\n",
              "1654     5  This was a flavor that I went to if I really w...\n",
              "2608     5  This flavor and chunky monkey are by far my fa...\n",
              "2733     4  Good ice cream. The best CC ice cream is from ...\n",
              "\n",
              "[7943 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85e_KlHHn1G_"
      },
      "source": [
        "I wanted to change the five star ratings to a classification of either positive or negative sentiment. To do this, I first started by mapping the string numbers into integers starting from 0. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaXu-QRq0r49",
        "outputId": "f67da696-12e6-4b93-cdd4-454c6bc06abf"
      },
      "source": [
        "class_mapping = {label: idx for idx, label in enumerate(np.unique(df['stars']))}\n",
        "class_mapping"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6EtIoLx0r49"
      },
      "source": [
        "#Converts the current class labels\n",
        "df['stars'] = df['stars'].map(class_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "tMY1g_GB0r4-",
        "outputId": "ff1618f1-b6e3-4184-df08-bed66d5a26da"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4838</th>\n",
              "      <td>4</td>\n",
              "      <td>I bought this a week ago for the first time an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>4</td>\n",
              "      <td>My mom and I always get this one every time we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>4</td>\n",
              "      <td>Searched high and low for this flavor. Finally...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5167</th>\n",
              "      <td>4</td>\n",
              "      <td>My favorite mint ice cream on the market and I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1727</th>\n",
              "      <td>4</td>\n",
              "      <td>First of all everyone should try ice cream fla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4932</th>\n",
              "      <td>4</td>\n",
              "      <td>I picked this up with the Red, White and blueb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265</th>\n",
              "      <td>2</td>\n",
              "      <td>Ben and Jerry's is my splurging ice cream. Onc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1654</th>\n",
              "      <td>4</td>\n",
              "      <td>This was a flavor that I went to if I really w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2608</th>\n",
              "      <td>4</td>\n",
              "      <td>This flavor and chunky monkey are by far my fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2733</th>\n",
              "      <td>3</td>\n",
              "      <td>Good ice cream. The best CC ice cream is from ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7943 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      stars                                               text\n",
              "4838      4  I bought this a week ago for the first time an...\n",
              "163       4  My mom and I always get this one every time we...\n",
              "972       4  Searched high and low for this flavor. Finally...\n",
              "5167      4  My favorite mint ice cream on the market and I...\n",
              "1727      4  First of all everyone should try ice cream fla...\n",
              "...     ...                                                ...\n",
              "4932      4  I picked this up with the Red, White and blueb...\n",
              "3265      2  Ben and Jerry's is my splurging ice cream. Onc...\n",
              "1654      4  This was a flavor that I went to if I really w...\n",
              "2608      4  This flavor and chunky monkey are by far my fa...\n",
              "2733      3  Good ice cream. The best CC ice cream is from ...\n",
              "\n",
              "[7943 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GGytzFFoEcp"
      },
      "source": [
        "Next, I used the integer mappings to loc the star column values as either 0, for negative, or 1, for positive. I decided to have the negative class range from 1 to 3 stars and the positive 4 or 5 stars. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEWrujuQ0r4-"
      },
      "source": [
        "df.loc[df[\"stars\"] == 0, \"stars\"]=0\n",
        "df.loc[df[\"stars\"] == 1, \"stars\"]=0\n",
        "df.loc[df[\"stars\"]==2, \"stars\"]=0\n",
        "df.loc[df[\"stars\"] == 3, \"stars\"]=1\n",
        "df.loc[df[\"stars\"] == 4, \"stars\"]=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "w1EYAV2j0r4-",
        "outputId": "9a1cb10e-0310-428b-b47f-bf19dc6b1850"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4838</th>\n",
              "      <td>1</td>\n",
              "      <td>I bought this a week ago for the first time an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>1</td>\n",
              "      <td>My mom and I always get this one every time we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>1</td>\n",
              "      <td>Searched high and low for this flavor. Finally...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5167</th>\n",
              "      <td>1</td>\n",
              "      <td>My favorite mint ice cream on the market and I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1727</th>\n",
              "      <td>1</td>\n",
              "      <td>First of all everyone should try ice cream fla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4932</th>\n",
              "      <td>1</td>\n",
              "      <td>I picked this up with the Red, White and blueb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265</th>\n",
              "      <td>0</td>\n",
              "      <td>Ben and Jerry's is my splurging ice cream. Onc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1654</th>\n",
              "      <td>1</td>\n",
              "      <td>This was a flavor that I went to if I really w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2608</th>\n",
              "      <td>1</td>\n",
              "      <td>This flavor and chunky monkey are by far my fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2733</th>\n",
              "      <td>1</td>\n",
              "      <td>Good ice cream. The best CC ice cream is from ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7943 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      stars                                               text\n",
              "4838      1  I bought this a week ago for the first time an...\n",
              "163       1  My mom and I always get this one every time we...\n",
              "972       1  Searched high and low for this flavor. Finally...\n",
              "5167      1  My favorite mint ice cream on the market and I...\n",
              "1727      1  First of all everyone should try ice cream fla...\n",
              "...     ...                                                ...\n",
              "4932      1  I picked this up with the Red, White and blueb...\n",
              "3265      0  Ben and Jerry's is my splurging ice cream. Onc...\n",
              "1654      1  This was a flavor that I went to if I really w...\n",
              "2608      1  This flavor and chunky monkey are by far my fa...\n",
              "2733      1  Good ice cream. The best CC ice cream is from ...\n",
              "\n",
              "[7943 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tZobru7H_Xi"
      },
      "source": [
        "The data is saved into a new csv file below so that the row indeces will start at 0 again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DL3dOXHIK8Y"
      },
      "source": [
        "df.to_csv(google_file_prefix + 'bj_data.csv', index=False, encoding='utf-8',)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc5v8kBDIbac"
      },
      "source": [
        "This results in the following dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0n-ZEZpIUxg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "a13e7576-8bab-495d-f326-256c6e0eba3e"
      },
      "source": [
        "df = pd.read_csv(google_file_prefix + 'bj_data.csv', encoding='utf-8')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>I bought this a week ago for the first time an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>My mom and I always get this one every time we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Searched high and low for this flavor. Finally...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>My favorite mint ice cream on the market and I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>First of all everyone should try ice cream fla...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   stars                                               text\n",
              "0      1  I bought this a week ago for the first time an...\n",
              "1      1  My mom and I always get this one every time we...\n",
              "2      1  Searched high and low for this flavor. Finally...\n",
              "3      1  My favorite mint ice cream on the market and I...\n",
              "4      1  First of all everyone should try ice cream fla..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI-FWfrUKsPg"
      },
      "source": [
        "Before the text data can be used in a machine learning model, it must be cleaned. The following code block defines a function the cleans the text by removing all of the unwanted characters and converting the text to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3RER8MELe1m"
      },
      "source": [
        "def preprocessor(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
        "                           text)\n",
        "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
        "            ' '.join(emoticons).replace('-', ''))\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RizJQBtGL9m9"
      },
      "source": [
        "Now this function can be applied to the text column in the data frame. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBFTQY-EMDQv"
      },
      "source": [
        "df['text'] = df['text'].apply(preprocessor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8h2nlgWVYE9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "e873ac50-b4ee-4eed-8855-d5e5a93d547a"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>i bought this a week ago for the first time an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>my mom and i always get this one every time we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>searched high and low for this flavor finally ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>my favorite mint ice cream on the market and i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>first of all everyone should try ice cream fla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7938</th>\n",
              "      <td>1</td>\n",
              "      <td>i picked this up with the red white and bluebe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7939</th>\n",
              "      <td>0</td>\n",
              "      <td>ben and jerry s is my splurging ice cream once...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7940</th>\n",
              "      <td>1</td>\n",
              "      <td>this was a flavor that i went to if i really w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7941</th>\n",
              "      <td>1</td>\n",
              "      <td>this flavor and chunky monkey are by far my fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7942</th>\n",
              "      <td>1</td>\n",
              "      <td>good ice cream the best cc ice cream is from p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7943 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      stars                                               text\n",
              "0         1  i bought this a week ago for the first time an...\n",
              "1         1  my mom and i always get this one every time we...\n",
              "2         1  searched high and low for this flavor finally ...\n",
              "3         1  my favorite mint ice cream on the market and i...\n",
              "4         1  first of all everyone should try ice cream fla...\n",
              "...     ...                                                ...\n",
              "7938      1  i picked this up with the red white and bluebe...\n",
              "7939      0  ben and jerry s is my splurging ice cream once...\n",
              "7940      1  this was a flavor that i went to if i really w...\n",
              "7941      1  this flavor and chunky monkey are by far my fa...\n",
              "7942      1  good ice cream the best cc ice cream is from p...\n",
              "\n",
              "[7943 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ze_jjA0ogCZ"
      },
      "source": [
        "The following cell defines and applies a bag of words model to the text in the dataframe by utilizing scikit learn's Count Vectorizer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfAWDqZ_74Zy"
      },
      "source": [
        "count = CountVectorizer()\n",
        "bag = count.fit_transform(df.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZekMu48douBG"
      },
      "source": [
        "This raw term frequencies from the Count Vectorizer are then used to construct a Term Frequency Inverse Document Frequency transformer that is implemented to downweight frequently occuring words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWWKwhHaYCv6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31b9a3be-3fb5-4154-ea4b-f4453566d4e7"
      },
      "source": [
        "tfidf = TfidfTransformer(use_idf=True, norm=None, smooth_idf=True)\n",
        "raw_tfidf = tfidf.fit_transform(count.fit_transform(df['text'])).toarray()\n",
        "raw_tfidf "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhDrSE16pMm8"
      },
      "source": [
        "Adjusts the TFIDF data using L2 normalization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erVEZRpcWDuA",
        "outputId": "bf0a0e28-f84b-4701-a9fb-9a1866e05d2b"
      },
      "source": [
        "l2_tfidf = raw_tfidf / np.sqrt(np.sum(raw_tfidf**2))\n",
        "l2_tfidf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA-MXBpNpuk9"
      },
      "source": [
        "From the resulting arrays above, it was difficult to see whether they were completely filled with zeros or not. To ensure that they had some numerical values, I used numpy's any function, which returns true if there are any nonzero elements in the array. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a17ewaMTDZc",
        "outputId": "b984bf3e-9790-46c9-f4e2-deb6a6f469f6"
      },
      "source": [
        "np.any(l2_tfidf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsZXf0_AUhew",
        "outputId": "06b62cdb-f8d2-45be-c91b-318a4810e166"
      },
      "source": [
        "np.any(raw_tfidf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UL3MBKXp_UW"
      },
      "source": [
        "The following functions are used to tokenize the data. The Natural Language Tool Kit's function, PorterStemmer, is used to trim the end of words such as 'talking' to 'talk'. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ0_IWEMWF1M"
      },
      "source": [
        "porter = PorterStemmer()\n",
        "\n",
        "def tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdJqeX8Uq3yp"
      },
      "source": [
        "Removes the stop words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ34WgEcW_rR",
        "outputId": "56d8bc6e-f905-4dfa-912a-975a39ff6584"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI6S6FcAuII5"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "for i in df[\"text\"]:\n",
        "  [w for w in tokenizer_porter(i) if w not in stop]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ouPNIloq64C"
      },
      "source": [
        "This cell splits the dataset into training and testing data. I decided to use a 30% test size. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-02yReY2YJVK",
        "outputId": "b8fd18ad-8613-464c-c64d-606023ec63ef"
      },
      "source": [
        "X_train = df.loc[:5560, 'text'].values\n",
        "y_train = df.loc[:5560, 'stars'].values\n",
        "X_test = df.loc[5560:, 'text'].values\n",
        "y_test = df.loc[5560:, 'stars'].values\n",
        "print(\"Ratio of training to testing data: \", len(X_train), \"/\", len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ratio of training to testing data:  5561 / 2383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJK358pI_dxu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a3c91a-3d81-480d-ec31-827de547caba"
      },
      "source": [
        "print(X_train[1000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "if my husband and i want a snack on cheat day this is our at home go to its simple yet amazing and its hard to stop eating it \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZyNKpfQ_igz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f06b00-dd6e-4cf3-f593-16662e0ed821"
      },
      "source": [
        "print(y_train[1000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j97waUeYz1Fi",
        "outputId": "1b5988a6-4073-46f8-ab9c-0b0d6af54003"
      },
      "source": [
        "print(X_train[1006])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "not very flavorful the shortbread adds a gritty mushy texture i couldn t taste raspberry the blueberry was dull the strawberry just didn t work in the mix \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmRVz6VKznfB",
        "outputId": "efa41da4-962f-4d87-b7ba-17b155330d64"
      },
      "source": [
        "print(y_train[1006])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEh56xZ1rbYH"
      },
      "source": [
        "# <center><b>Model Optimization and Serialization</b></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsVIcX6wrsjR"
      },
      "source": [
        "The following code defines a parameter grid for the grid search. I am using a SGD Classifier, the Count Vectorizer defined above, and the TFIDF transformer defined above in a pipeline. The grid search incorporates different options for each element in the pipeline. For the SGD Classifier, the alpha value, type of loss, and penalty type are varied. The use of stop words and the ngram range are changed for the Count Vectorizer. Finally, for the TFIDF transformer, the use of the 'idf' is varied. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yod_-g8nYy9V"
      },
      "source": [
        "param_grid = [{'vect__stop_words': [stop, None],\n",
        "               'vect__ngram_range': ((1, 1), (1, 2)),\n",
        "               'clf__alpha': [0.001, 0.005, 0.01, 0.1, 0.5, 1, 5, 10, 50, 100],\n",
        "               'clf__loss': ['log', 'hinge', 'perceptron'],\n",
        "               'clf__penalty': ['l1', 'l2']},\n",
        "              {'vect__ngram_range': ((1, 1), (1, 2)),\n",
        "               'vect__stop_words': [stop, None],\n",
        "               'tfidf__use_idf':[True, False],\n",
        "               'tfidf__norm':[None,'l1', 'l2'],\n",
        "               'clf__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 1, 5, 10, 50, 100],\n",
        "               'clf__loss': ['log', 'hinge', 'perceptron'],\n",
        "               'clf__penalty': ['l1', 'l2']}]\n",
        "sgd_tfidf = Pipeline([('vect', count),\n",
        "                      ('tfidf', tfidf),\n",
        "                      ('clf', SGDClassifier())])\n",
        "\n",
        "gs_sgd_tfidf = GridSearchCV(sgd_tfidf, param_grid,\n",
        "                           scoring='accuracy',\n",
        "                           cv=5,\n",
        "                           verbose=2,\n",
        "                           n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CatC7dR0DnVB"
      },
      "source": [
        "The grid search is fitted to the training data in order to find the best hyperparameters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvtD5FuAY4dE",
        "outputId": "2dd49bba-bb9d-43c4-b2fa-029707068889"
      },
      "source": [
        "gs_sgd_tfidf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1680 candidates, totalling 8400 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   33.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=-1)]: Done 1009 tasks      | elapsed: 10.2min\n",
            "[Parallel(n_jobs=-1)]: Done 1454 tasks      | elapsed: 13.6min\n",
            "[Parallel(n_jobs=-1)]: Done 1981 tasks      | elapsed: 18.1min\n",
            "[Parallel(n_jobs=-1)]: Done 2588 tasks      | elapsed: 23.0min\n",
            "[Parallel(n_jobs=-1)]: Done 3277 tasks      | elapsed: 28.8min\n",
            "[Parallel(n_jobs=-1)]: Done 4046 tasks      | elapsed: 34.1min\n",
            "[Parallel(n_jobs=-1)]: Done 4897 tasks      | elapsed: 39.8min\n",
            "[Parallel(n_jobs=-1)]: Done 5828 tasks      | elapsed: 45.9min\n",
            "[Parallel(n_jobs=-1)]: Done 6841 tasks      | elapsed: 52.7min\n",
            "[Parallel(n_jobs=-1)]: Done 7934 tasks      | elapsed: 59.8min\n",
            "[Parallel(n_jobs=-1)]: Done 8400 out of 8400 | elapsed: 62.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vect',\n",
              "                                        CountVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.int64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 1),\n",
              "                                                        preprocessor=None,\n",
              "                                                        stop_words=None,\n",
              "                                                        strip_accents=None,\n",
              "                                                        token_pattern='(?u)...\n",
              "                          'vect__ngram_range': ((1, 1), (1, 2)),\n",
              "                          'vect__stop_words': [['i', 'me', 'my', 'myself', 'we',\n",
              "                                                'our', 'ours', 'ourselves',\n",
              "                                                'you', \"you're\", \"you've\",\n",
              "                                                \"you'll\", \"you'd\", 'your',\n",
              "                                                'yours', 'yourself',\n",
              "                                                'yourselves', 'he', 'him',\n",
              "                                                'his', 'himself', 'she',\n",
              "                                                \"she's\", 'her', 'hers',\n",
              "                                                'herself', 'it', \"it's\", 'its',\n",
              "                                                'itself', ...],\n",
              "                                               None]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pooA_VNNsrjg"
      },
      "source": [
        "The best parameters from the grid search are printed and used to give the CV accuracy for the pipeline. The best parameters for the pipeline are:\n",
        "\n",
        "\n",
        "\n",
        "1.   For the SGD Classifier:\n",
        "\n",
        "\n",
        "  *   Alpha: 0.1\n",
        "  *   Loss: hinge\n",
        "  *   Penalty: L2\n",
        "\n",
        "\n",
        "2.   For the Count Vectorizer:\n",
        "\n",
        "*   N Gram Range: (1,2)\n",
        "*   Stop Words: none\n",
        "\n",
        "3. For the TFIDF Vectorizer:\n",
        "\n",
        "*   Norm: None\n",
        "*   Use IDF: True\n",
        "\n",
        "\n",
        "\n",
        "Additionally, the optimized pipeline performed very well in terms of accuracy, scoring 92.4%. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CehZmrGY8cu",
        "outputId": "2d1e9781-4384-49e5-ece4-ba4d1477bcc0"
      },
      "source": [
        "print('Best parameter set: %s ' % gs_sgd_tfidf.best_params_)\n",
        "print('CV Accuracy: %.3f' % gs_sgd_tfidf.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameter set: {'clf__alpha': 0.1, 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'tfidf__norm': None, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2), 'vect__stop_words': None} \n",
            "CV Accuracy: 0.924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4iIIURbs1NP"
      },
      "source": [
        "The classifier is set with the grid search results and scored based on the unseen testing data. It also performed quite well with an accuracy of 92.1%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8wMG9GqZAvN",
        "outputId": "1d5540ba-e7f0-45fa-93bc-7a34e9c698ea"
      },
      "source": [
        "clf = gs_sgd_tfidf.best_estimator_\n",
        "print('Test Accuracy: %.3f' % clf.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsU97SVrGJ1x"
      },
      "source": [
        "The following block uses an out-of-core learning method to clean, process, stream, vectorize, and model the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_ESF8AAZDe3",
        "outputId": "5fd00680-4ed6-4659-cf95-d69765fe3431"
      },
      "source": [
        "stop = stopwords.words('english')\n",
        "porter = PorterStemmer()\n",
        "\n",
        "def tokenizer(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
        "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
        "    tokenized = [w for w in text.split() if w not in stop]\n",
        "    return tokenized\n",
        "\n",
        "def stream_docs(path):\n",
        "    with open(path, 'r', encoding='utf-8') as csv:\n",
        "        next(csv) # skip header\n",
        "        for line in csv:\n",
        "          if line[0].isnumeric() :\n",
        "            text, label = line[2:], int(line[0])\n",
        "            yield text, label\n",
        "variable = stream_docs(path=google_file_prefix + 'bj_data.csv')\n",
        "def get_minibatch(doc_stream, size):\n",
        "  docs, y = [], []\n",
        "  for _ in range(size):\n",
        "    foo = next(doc_stream)\n",
        "    text, label = foo[0], foo[1]\n",
        "    docs.append(text)\n",
        "    y.append(label)\n",
        "  return docs, y\n",
        "\n",
        "vect = HashingVectorizer(decode_error='ignore', \n",
        "                         n_features=2**21,\n",
        "                         preprocessor=None, \n",
        "                         tokenizer=tokenizer)\n",
        "\n",
        "clf = SGDClassifier(loss='log', random_state=1, max_iter=1)\n",
        "doc_stream = stream_docs(path=google_file_prefix + 'bj_data.csv')\n",
        "print(next(doc_stream))\n",
        "import pyprind\n",
        "\n",
        "classes = np.array([0, 1, 2])\n",
        "X, y = get_minibatch(doc_stream, size=7942)\n",
        "X_train, y_train = X[:5560], y[:5560]\n",
        "X_test, y_test = X[5560:], y[5560:]\n",
        "if not X_train:\n",
        "  print('break')\n",
        "X_train = vect.transform(X_train)\n",
        "clf.partial_fit(X_train, y_train, classes=[0, 1, 2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('I bought this a week ago for the first time and instantly fell in love. The combination is epic!\\n', 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1,\n",
              "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
              "              random_state=1, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
              "              verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLG3jDNWZmkq",
        "outputId": "9d3a9cc8-6b2a-4df6-b6f7-90192405460c"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7943"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWI0EgCYZpGx",
        "outputId": "66248353-e87b-4140-a642-c1a54643e10b"
      },
      "source": [
        "X_test = vect.transform(X_test)\n",
        "print('Accuracy: %.3f' % clf.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MlLyEdkZsUB",
        "outputId": "a1c2af64-9e00-4cb0-a30b-82957d084230"
      },
      "source": [
        "clf = clf.fit(X_test, y_test)\n",
        "clf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1,\n",
              "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
              "              random_state=1, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
              "              verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e_CTPsWtfdg"
      },
      "source": [
        "## Serializing the Trained Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCvgCiwUe_E8"
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlzexlBmIA7L"
      },
      "source": [
        "The following section creates a standalone Python file that is used in making a Flask application in the next section. It implements a hashing vectorizer using the optimized tfidf vectorizer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nPqgdNnZ0Sg"
      },
      "source": [
        "#Gets the destination for the pickled objects. \n",
        "dest = os.path.join(google_file_prefix + 'creamyclassifier', 'pkl_objects')\n",
        "#Creates the directory\n",
        "if not os.path.exists(dest):\n",
        "    os.makedirs(dest)\n",
        "#Adds the pickled stop and classifier objects to the destination\n",
        "pickle.dump(stop, open(os.path.join(dest, 'stopwords.pkl'), 'wb'), protocol=4)   \n",
        "pickle.dump(clf, open(os.path.join(dest, 'classifier.pkl'), 'wb'), protocol=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQVKcQcsZ29Y"
      },
      "source": [
        "os.chdir(google_file_prefix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFVavllodBbg"
      },
      "source": [
        "Writes the vectorizer file that will conain the tokenizer and hashing vectorizer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urjra-8kZ_mi",
        "outputId": "9df816dc-56e3-472c-bf6a-c2f8d141d584"
      },
      "source": [
        "%%writefile creamyclassifier/vectorizer.py\n",
        "#Gets the current directory of the file. \n",
        "cur_dir = os.path.dirname(__file__)\n",
        "#Loads the stopword data pickled earlier. \n",
        "stop = pickle.load(open(os.path.join(\n",
        "                cur_dir,\n",
        "                'pkl_objects', \n",
        "                'stopwords.pkl'), 'rb'))\n",
        "#Tokenizer function that cleans the text data and removes the stop words. \n",
        "def tokenizer(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
        "                           text.lower())\n",
        "    text = re.sub('[\\W]+', ' ', text.lower()) \\\n",
        "                   + ' '.join(emoticons).replace('-', '')\n",
        "    tokenized = [w for w in text.split() if w not in stop]\n",
        "    return tokenized\n",
        "#Hashing vectorizer that uses the tokenizer above. \n",
        "vect = HashingVectorizer(decode_error='ignore',\n",
        "                         n_features=2**21,\n",
        "                         preprocessor=None,\n",
        "                         tokenizer=tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting creamyclassifier/vectorizer.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW7VBWcXaA-g"
      },
      "source": [
        "os.chdir(google_file_prefix + 'creamyclassifier')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zks8YONBaFCs"
      },
      "source": [
        "#Imports the hashing vectorizer created above. \n",
        "from vectorizer import vect\n",
        "#Loads the classifier that was pickled earlier. \n",
        "clf = pickle.load(open(os.path.join('pkl_objects', 'classifier.pkl'), 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDf_hT2Ec6N3"
      },
      "source": [
        "Examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJr-4WhUaKUC",
        "outputId": "a7a1a745-d502-4fa9-d5bf-f4e106bc510d"
      },
      "source": [
        "label = {0:'negative', 1:'positive'}\n",
        "\n",
        "example = [\"I love this flavor. It's amazing.\"]\n",
        "X = vect.transform(example)\n",
        "print('Prediction: %s\\nProbability: %.2f%%' %\\\n",
        "      (label[clf.predict(X)[0]], \n",
        "       np.max(clf.predict_proba(X))*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: positive\n",
            "Probability: 99.77%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3VSmUP95fku",
        "outputId": "4f3ec4bf-aabc-4b5f-b168-35115b4bc460"
      },
      "source": [
        "ex2 = [\"I hate this icecream! It's horrible\"]\n",
        "X2 = vect.transform(ex2)\n",
        "print(\"Prediction: %s\\nProbability: %.2f%%\" %\\\n",
        "      (label[clf.predict(X2)[0]],\n",
        "       np.max(clf.predict_proba(X2))*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: negative\n",
            "Probability: 58.97%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_qesX9FJZHm"
      },
      "source": [
        "# <center><b>Website Creation and Publishing</b></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xq3puZi0BcR"
      },
      "source": [
        "## SQLite Database:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IIfwtg6Y0IbO",
        "outputId": "113f11c7-427e-4199-b2a4-9418b76f17f6"
      },
      "source": [
        "os.getcwd() #Gets the current working directory"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/machine-learning/Project Two Jordan Sinclair/creamyclassifier'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_fKVtbQ0PIh"
      },
      "source": [
        "#Connects to the database and gets the cursor. \n",
        "conn = sqlite3.connect('reviews.sqlite')\n",
        "c = conn.cursor()\n",
        "#Sets up the table for the review and sentiment data\n",
        "c.execute('DROP TABLE IF EXISTS review_db')\n",
        "c.execute('CREATE TABLE review_db (review TEXT, sentiment INTEGER)')\n",
        "#Examples:\n",
        "example1 = 'I love this flavor'\n",
        "c.execute(\"INSERT INTO review_db (review, sentiment) VALUES (?, ?)\", (example1, 1))\n",
        "\n",
        "example2 = 'This flavor was not good'\n",
        "c.execute(\"INSERT INTO review_db (review, sentiment) VALUES (?, ?)\", (example2, 0))\n",
        "#Closes the connection\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxVsDFW41huN"
      },
      "source": [
        "#Connects to the database again and gets the cursor. \n",
        "conn = sqlite3.connect('reviews.sqlite')\n",
        "c = conn.cursor()\n",
        "#Gets all of the data input into the database. \n",
        "c.execute(\"SELECT * FROM review_db\")\n",
        "results = c.fetchall()\n",
        "#Closes the connection\n",
        "conn.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwTtDIAG10Yh",
        "outputId": "cb6a2b28-3adf-49d3-a4e6-64b18d2ae888"
      },
      "source": [
        "#Prints the results from the database. \n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('I love this flavor', 1), ('This flavor was not good', 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Slpp3ckF1-ch"
      },
      "source": [
        "## Flask Application:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65JAQg6YeW_5"
      },
      "source": [
        "The link to my website is:\n",
        "\n",
        "http://artengine.pythonanywhere.com/\n",
        "\n"
      ]
    }
  ]
}